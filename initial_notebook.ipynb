{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f49ad27",
   "metadata": {},
   "source": [
    "# Telco Churn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e51a27",
   "metadata": {},
   "source": [
    "### image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "782a46d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# classification models\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# custom modules\n",
    "import modeling as md\n",
    "import prepare\n",
    "import acquire\n",
    "import exploration\n",
    "import split\n",
    "\n",
    "# global variable, will never change\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf6e37b",
   "metadata": {},
   "source": [
    "# Project Planning (readme)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0723bbed",
   "metadata": {},
   "source": [
    "* Create acquire.py module to obtain data from the codeup database, cache them for later use.\n",
    "* Create prepare.py module to prepare/clean the data (handling missing values, encoding for the model, etc.)\n",
    "* Create/use functions to explore variables through visualization and statistical testing, write down any insights gained through both methods. Hypothesis required for each statistical test.\n",
    "* Establish baseline accuracy for our target variable.\n",
    "* Create several models using training data, then evaluate the models on both training and validate data.\n",
    "* Take the best performing model and test it on the test data.\n",
    "* At the same time, save the predictions to a csv with the values of customer_id, the probability of our target variable, and the model's prediction.\n",
    "* Document conclusions, takeaways, and recommendations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6d7949",
   "metadata": {},
   "source": [
    "## Project Overview:\n",
    "\n",
    "### What? \n",
    "Discover key drivers of churn, make a predictive model of how likely someone is to churn.\n",
    "\n",
    "### Why? \n",
    "Make data-driven business changes to target our highest areas of opportunity to create the most financial gain/impact.\n",
    "\n",
    "### How? \n",
    "Acquire data, clean it, explore it, model it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc06553b",
   "metadata": {},
   "source": [
    "# Executive Summary - Findings & Next Steps\n",
    "\n",
    "Key Drivers of Churn: Fiber, Electronic Check, Monthly Charges\n",
    "\n",
    "#### Recommendations: \n",
    "- Text reminders of upcoming bills\n",
    "- small rebate for autopay\n",
    "- normalization of monthly charges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b27b25",
   "metadata": {},
   "source": [
    "# Acquire Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16fa3e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 25 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Unnamed: 0                7043 non-null   int64  \n",
      " 1   contract_type_id          7043 non-null   int64  \n",
      " 2   payment_type_id           7043 non-null   int64  \n",
      " 3   internet_service_type_id  7043 non-null   int64  \n",
      " 4   customer_id               7043 non-null   object \n",
      " 5   gender                    7043 non-null   object \n",
      " 6   senior_citizen            7043 non-null   int64  \n",
      " 7   partner                   7043 non-null   object \n",
      " 8   dependents                7043 non-null   object \n",
      " 9   tenure                    7043 non-null   int64  \n",
      " 10  phone_service             7043 non-null   object \n",
      " 11  multiple_lines            7043 non-null   object \n",
      " 12  online_security           7043 non-null   object \n",
      " 13  online_backup             7043 non-null   object \n",
      " 14  device_protection         7043 non-null   object \n",
      " 15  tech_support              7043 non-null   object \n",
      " 16  streaming_tv              7043 non-null   object \n",
      " 17  streaming_movies          7043 non-null   object \n",
      " 18  paperless_billing         7043 non-null   object \n",
      " 19  monthly_charges           7043 non-null   float64\n",
      " 20  total_charges             7043 non-null   object \n",
      " 21  churn                     7043 non-null   object \n",
      " 22  internet_service_type     7043 non-null   object \n",
      " 23  payment_type              7043 non-null   object \n",
      " 24  contract_type             7043 non-null   object \n",
      "dtypes: float64(1), int64(6), object(18)\n",
      "memory usage: 1.3+ MB\n",
      "None\n",
      "                           count         mean          std    min     25%  \\\n",
      "Unnamed: 0                7043.0  3521.000000  2033.283305   0.00  1760.5   \n",
      "contract_type_id          7043.0     1.690473     0.833755   1.00     1.0   \n",
      "payment_type_id           7043.0     2.315633     1.148907   1.00     1.0   \n",
      "internet_service_type_id  7043.0     1.872923     0.737796   1.00     1.0   \n",
      "senior_citizen            7043.0     0.162147     0.368612   0.00     0.0   \n",
      "tenure                    7043.0    32.371149    24.559481   0.00     9.0   \n",
      "monthly_charges           7043.0    64.761692    30.090047  18.25    35.5   \n",
      "\n",
      "                              50%      75%      max  \n",
      "Unnamed: 0                3521.00  5281.50  7042.00  \n",
      "contract_type_id             1.00     2.00     3.00  \n",
      "payment_type_id              2.00     3.00     4.00  \n",
      "internet_service_type_id     2.00     2.00     3.00  \n",
      "senior_citizen               0.00     0.00     1.00  \n",
      "tenure                      29.00    55.00    72.00  \n",
      "monthly_charges             70.35    89.85   118.75  \n"
     ]
    }
   ],
   "source": [
    "# Queues the sql database for telco data and writes to csv.\n",
    "# Only reads the csv if it exists\n",
    "telco_df = acquire.get_telco_data()\n",
    "\n",
    "# define target variable\n",
    "target_var = 'churn_Yes'\n",
    "\n",
    "# show info/standard statistics for the dataframe\n",
    "print(telco_df.info())\n",
    "print(telco_df.describe().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feecc969",
   "metadata": {},
   "source": [
    "Acquire keypoints:\n",
    "   - Wrote SQL to queue the Codeup database, write the results to csv. If csv already\n",
    "      exists, read from csv instead.\n",
    "    - The initial dataframe has 25 columns and 7043 rows.\n",
    "    - Both monthly and total charges are the same unit of measure, although tenure is not.\n",
    "    - Total charges also has a much higher range than both monthly_charges and tenure.           Scaling might be worth exploring in the future.\n",
    "    - Total charges has a datatype of 'object' when it should be float. Fix in prepare."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6828800",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2980f832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7032, 24)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns clean dataframe, quantitative/categorical columns for \n",
    "# future function use. \n",
    "telco_df, categories, quant_cols, u_df = prepare.prep_telco(telco_df)\n",
    "telco_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb1c7ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training, validate and test splits\n",
    "train, validate, test = split.train_validate_test_split(u_df, 'churn')\n",
    "train_en, validate_en, test_en = prepare.encode_train_validate_test(u_df, train.drop(columns='customer_id'), \n",
    "                                                                    validate.drop(columns='customer_id'),\n",
    "                                                                    test.drop(columns='customer_id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828af53c",
   "metadata": {},
   "source": [
    "Preparation Takeaways:\n",
    "   - There were some 0 values in total_charges that did not make sense to keep, so they were dropped (7043 -> 7032 rows).\n",
    "   - Converted total_charges to 'float64' so it would be possible to do math and to model with it.\n",
    "   - Created train, validate and test splits for in-sample testing/exploration, out-of-sample testing, and final model testing.\n",
    "   - Encoded each train, validate and test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a11796c",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bb3ede",
   "metadata": {},
   "source": [
    "### visualizations and takeaways \n",
    "\n",
    "### statistical testing, hypothesis, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e58b8de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85764fb0",
   "metadata": {},
   "source": [
    "# Model and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c18f70d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy (Churn = 0): 73.42999999999999%\n"
     ]
    }
   ],
   "source": [
    "# set baseline\n",
    "md.Results.baseline = (train_en.churn_Yes==0).mean()\n",
    "print(f'Baseline accuracy (Churn = 0): {round(md.Results.baseline, 4) * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cfc3f4",
   "metadata": {},
   "source": [
    "If I predicted that someone would not churn, I'd have an accuracy of 73.43%\n",
    "That is the baseline accuracy that I am trying to outperform.\n",
    "\n",
    "I'm going to try Logistic Regression, Random Forests, Decision Trees, and KNearest Neighbors to try and create a predicitve classification model.\n",
    "\n",
    "I've written functions to adjust the parameters for the following:\n",
    "   - Decision Trees: \n",
    "        - depth\n",
    "   - Random Forests:\n",
    "        - depth\n",
    "        - min samples leaf\n",
    "   - KNearestNeighbor:\n",
    "        - n_neighbors\n",
    "        - weights (uniform, distance)\n",
    "   - Logistic Regression:\n",
    "        - C\n",
    "        - solver (lbgfs, liblinear)\n",
    "        - fit_intercept, intercept_scaling\n",
    "        \n",
    "Random State set to 123 where possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e60f71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create iterations of models, group them into Result objects that I made in modeling.py\n",
    "dt_mods, rf_mods, knn_mods, lr_mods = md.all_reports(train_en, validate_en, test_en, target_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1040ab95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "      <th>percent_diff</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>n_nearest_neighbor</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>decision_tree</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.800610</td>\n",
       "      <td>0.777844</td>\n",
       "      <td>0.022766</td>\n",
       "      <td>2.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_uniform</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.801372</td>\n",
       "      <td>0.775474</td>\n",
       "      <td>0.025898</td>\n",
       "      <td>3.23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic_regression</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.804420</td>\n",
       "      <td>0.796209</td>\n",
       "      <td>0.008211</td>\n",
       "      <td>1.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_forests</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.822200</td>\n",
       "      <td>0.795616</td>\n",
       "      <td>0.027174</td>\n",
       "      <td>3.33</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     depth  train_accuracy  validate_accuracy  difference  \\\n",
       "model_type                                                                  \n",
       "decision_tree          4.0        0.800610           0.777844    0.022766   \n",
       "knn_uniform            NaN        0.801372           0.775474    0.025898   \n",
       "logistic_regression    NaN        0.804420           0.796209    0.008211   \n",
       "random_forests         8.0        0.822200           0.795616    0.027174   \n",
       "\n",
       "                     percent_diff  min_samples_leaf  n_nearest_neighbor     C  \n",
       "model_type                                                                     \n",
       "decision_tree                2.84               NaN                 NaN   NaN  \n",
       "knn_uniform                  3.23               NaN                14.0   NaN  \n",
       "logistic_regression          1.02               NaN                 NaN  10.0  \n",
       "random_forests               3.33              15.0                 NaN   NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get highest performing model types while specifying a limiting % diff between train/validate\n",
    "md.Results.total_summary[md.Results.total_summary.percent_diff < 3.5].groupby('model_type').max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3542f3e",
   "metadata": {},
   "source": [
    "Takeaways from modeling:\n",
    "- all models seemed to beat baseline\n",
    "- knn_distance had so much variance that it wouldn't show up under the limiting condition of 3.5% difference between train and validate.\n",
    "- My logistic regression model performed best with a validate accuracy of 79.62%. This model beats baseline accuracy by 8.43% and is the model I'll use on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f164d6",
   "metadata": {},
   "source": [
    "# Test best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cddc38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression(C=10, random_state=123, fit_intercept=False, intercept_scaling=7.5)\n",
    "x_train = train_en.drop(columns=[target_var, 'customer_id'])\n",
    "y_train = train_en[target_var]\n",
    "\n",
    "logit = logit.fit(x_train, y_train)\n",
    "\n",
    "X_test = test_en.drop(columns=[target_var, 'customer_id'])\n",
    "Y_test = test_en[target_var]\n",
    "\n",
    "y_pred_test = logit.predict(X_test)\n",
    "\n",
    "accuracy = logit.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560330d1",
   "metadata": {},
   "source": [
    "Test Result Takeaways:\n",
    "   - Accuracy of 80.67% against test set, beating baseline by 9.86%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fe493c",
   "metadata": {},
   "source": [
    "# Create Predictions csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef46c8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_test = logit.predict_proba(X_test)\n",
    "churn_proba = proba_test[:,1]\n",
    "\n",
    "predictions = pd.DataFrame()\n",
    "predictions['customer_id'] = test_en.customer_id\n",
    "predictions['prediction'] = y_pred_test\n",
    "predictions['probability'] = churn_proba\n",
    "\n",
    "predictions.to_csv('predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd1f738",
   "metadata": {},
   "source": [
    "# Conclusions & Takeaways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701f4929",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
